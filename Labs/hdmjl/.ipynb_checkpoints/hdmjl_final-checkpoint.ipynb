{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66e85fa",
   "metadata": {},
   "source": [
    "# HDMJL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3072e9",
   "metadata": {},
   "source": [
    "# 1. Preliminary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92162901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for splitting data\n",
    "using Distributed\n",
    "\n",
    "@everywhere using LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, Tables, TableOperations, StatsBase, FreqTables, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bf7bd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvec (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function which turn a list or vector-like object into a proper two\n",
    "# dimensional column vector\n",
    "\n",
    "function cvec(a)\n",
    "    \"\"\" Turn a list or vector-like object into a proper column vector\n",
    "    Input\n",
    "    a: List or vector-like object, has to be a potential input for np.array()\n",
    "    Output\n",
    "    vec: two dimensional NumPy array, with the first dimension weakly greater\n",
    "         than the second (resulting in a column vector for a vector-like input)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Conver input into a two dimensional NumPy array\n",
    "    vec = cat([a], dims = 2) \n",
    "\n",
    "    # Check whether the second dimension is strictly greater than the first\n",
    "    # (remembering Python's zero indexing)\n",
    "    \n",
    "    if size(vec)[1] < size(vec)[2]\n",
    "        # If so, transpose the input vector\n",
    "        vec = transpose(vec)\n",
    "    end\n",
    "   \n",
    "    # Return the column vector\n",
    "    return vec\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd830368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corre (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Statistics.cor\n",
    "function corre(y, X)\n",
    "    \n",
    "    \"\"\" Return correlation coefficients between columns of matrices\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array\n",
    "    X: n by k NumPy array\n",
    "    Outputs\n",
    "    corr: list of length k, where the k-th element is the correlation\n",
    "          coefficient between y and the k-th column of X\n",
    "    \"\"\"\n",
    "    # Concatenate y and X into a single NumPy array\n",
    "    yX = hcat(y, X)\n",
    "    \n",
    "    # Get the correlation coefficients between all columns of that array\n",
    "    corr = cor(yX)\n",
    "    \n",
    "    # Get the first row, starting at the first off-diagonal element (these are\n",
    "    # the correlation coefficients between y and each column of X\n",
    "    corr = corr[1, :] \n",
    "    \n",
    "    # Return the result\n",
    "    return corr\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb4657a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_values (generic function with 3 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_values(X, y, number::Int64=5, intercetp::Bool=true)\n",
    "    \"\"\" Return an initial parameter guess for a LASSO model\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    X: n by k NumPy array, RHS variables\n",
    "    Outputs\n",
    "    residuals: n ny 1 NumPy array, residuals for initial parameter guess\n",
    "    coefficients: k by 1 NumPy array, initial coefficient values\n",
    "    \"\"\"\n",
    "    # Make sure y is a proper column vector\n",
    "    #y = cvec(y)\n",
    "    \n",
    "    # Get the absolute value of correlations between y and X\n",
    "    corr = broadcast(abs, cor(y, X)[1, :])\n",
    "    \n",
    "    # Get the number of columns of X\n",
    "    kx = size(X)[2]\n",
    "    \n",
    "    # Make an index selecting the five columns of X which are most correlated\n",
    "    # with y (since .argsort() always sorts in increasing order, selecting from\n",
    "    # the back gets the most highly correlated columns)\n",
    "    index = sortperm(corr, rev=true)[1: min(number, kx)]\n",
    "    \n",
    "    # Set up an array of coefficient guesses\n",
    "    coefficients = zeros(kx)\n",
    "    \n",
    "    # Regress y on the five most correlated columns of X, including an intercept\n",
    "    # if desired\n",
    "   reg = lm(X[:, index], y)\n",
    "    \n",
    "    # Replace the guesses for the estimated coefficients (note that .coef_ does\n",
    "    # not return the estimated intercept, if one was included in the model)\n",
    "    \n",
    "    coefficients[index] = GLM.coef(reg)\n",
    "    \n",
    "    # Replace any NANs as zeros\n",
    "    replace!(coefficients, NaN=>0)\n",
    "    \n",
    "    # Get the regression residuals\n",
    "    residuals = y - predict(reg, X[:, index])\n",
    "    \n",
    "    return residuals, reg, index, coefficients, corr\n",
    "    #return index\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cc1a5",
   "metadata": {},
   "source": [
    "# 2. LassoShooting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70384342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoShooting_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function LassoShooting_fit( x, y, lmbda, control::control, \n",
    "#                             XX = nothing, Xy = nothing, beta_start = nothing)\n",
    "\n",
    "function LassoShooting_fit( ;x, y, lmbda, maxIter::Int = 1000, \n",
    "                            optTol::Float64 = 10^(-5), \n",
    "                            zeroThreshold::Float64 = 10^(-6),\n",
    "                            XX = nothing, Xy = nothing, beta_start = nothing)\n",
    "        \n",
    "     \"\"\" Shooting LASSO algorithm with variable dependent penalty weights\n",
    "    Inputs\n",
    "    x: n by p NumPy array, RHS variables\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    lmbda: p by 1 NumPy array, variable dependent penalty terms. The j-th\n",
    "           element is the penalty term for the j-th RHS variable.\n",
    "    maxIter: integer, maximum number of shooting LASSO updated\n",
    "    optTol: scalar, algorithm terminated once the sum of absolute differences\n",
    "            between the updated and current weights is below optTol\n",
    "    zeroThreshold: scalar, if any final weights are below zeroThreshold, they\n",
    "                   will be set to zero instead\n",
    "    XX: k by k NumPy array, pre-calculated version of x'x\n",
    "    Xy: k by 1 NumPy array, pre-calculated version of x'y\n",
    "    beta_start: k by 1 NumPy array, initial weights\n",
    "    Outputs\n",
    "    w: k by 1 NumPy array, final weights\n",
    "    wp: k by m + 1 NumPy array, where m is the number of iterations the\n",
    "        algorithm took. History of weight updates, starting with the initial\n",
    "        weights.\n",
    "    m: integer, number of iterations the algorithm took\n",
    "    \"\"\"\n",
    "    n = size(x)[1]\n",
    "    p = size(x)[2]\n",
    "    \n",
    "    # Check whether XX and Xy were provided, calculate them if not\n",
    "    if (isnothing(XX))\n",
    "        XX = x'*x\n",
    "    end\n",
    "\n",
    "    if (isnothing(Xy))\n",
    "        Xy = x'*y\n",
    "    end\n",
    "\n",
    "    # Check whether an initial value for the intercept was provided\n",
    "\n",
    "    if (isnothing(beta_start))\n",
    "        # If not, use init_values from help_functions, which will return\n",
    "        # regression estimates for the five variables in x which are most\n",
    "        # correlated with y, and initialize all other coefficients as zero\n",
    "        beta = init_values(x, y)[4]\n",
    "\n",
    "    else\n",
    "        # Otherwise, use the provided initial weights\n",
    "        beta = beta_start\n",
    "    end\n",
    "\n",
    "    # Set up a history of weights over time, starting with the initial ones\n",
    "    wp = beta\n",
    "\n",
    "    # Keep track of the number of iterations\n",
    "    m = 1\n",
    "\n",
    "    # Create versions of XX and Xy which are just those matrices times two\n",
    "    XX2 = XX * 2\n",
    "    Xy2 = Xy * 2\n",
    "\n",
    "    #@unpack maxIter, optTol, zeroThreshold = control()\n",
    "\n",
    "    # Go through all iteration\n",
    "    while m<maxIter\n",
    "\n",
    "        # Save the last set of weights (the .copy() is important, otherwise\n",
    "        # beta_old will be updated every time beta is changed during the\n",
    "        # following loop)\n",
    "        beta_old = copy(beta)\n",
    "\n",
    "        # Go through all parameters\n",
    "        for j in 1:p\n",
    "            \n",
    "            # Calculate the shoot\n",
    "            S0 = sum( XX2[j, :].*beta ) - XX2[j, j].*beta[j] - Xy2[j]\n",
    "\n",
    "            # Update the weights\n",
    "            if sum(isnothing(XX)) >= 1\n",
    "                beta[j] = 0\n",
    "\n",
    "            elseif S0 >lmbda[j]\n",
    "                beta[j] = (lmbda[j] - S0) / XX2[j,j]\n",
    "\n",
    "            elseif S0 < -lmbda[j]\n",
    "                beta[j] = (-lmbda[j] - S0) / XX2[j,j]\n",
    "\n",
    "            elseif broadcast(abs, S0) <= lmbda[j]\n",
    "                beta[j] = 0\n",
    "\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Add the updated weights to the history of weights\n",
    "        wp = hcat(wp, beta)\n",
    "\n",
    "        # Check whether the weights are within tolerance\n",
    "        if sum(broadcast(abs, beta - beta_old)) < optTol\n",
    "            # If so, break the while loop\n",
    "            break\n",
    "        end\n",
    "\n",
    "        # Increase the iteration counter\n",
    "        m = m + 1\n",
    "    end\n",
    "\n",
    "    # Set the final weights to the last updated weights\n",
    "    w = beta   \n",
    "\n",
    "    # Set weights which are within zeroThreshold to zero\n",
    "    w[broadcast(abs, w) .< zeroThreshold] .= 0\n",
    "    \n",
    "    #return beta,  w\n",
    "    return Dict(\"coefficients\" => w, \"coef_list\" => wp, \"num_it\" => m)\n",
    "    #return w, wp, m\n",
    "    #return XX2, Xy2\n",
    "    \n",
    "\n",
    "end\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f6d4a",
   "metadata": {},
   "source": [
    "# 3.1 lambdaCalculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad5dfb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lambdaCalculation (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lambdaCalculation(     ; homoskedastic::Bool=false, X_dependent_lambda::Bool=false,\n",
    "                                lambda_start=nothing, c::Float64=1.1, gamma::Float64=0.1, \n",
    "                                numSim::Int=5000, y=nothing, x=nothing, par::Bool=true, \n",
    "                                corecap::Float64=Inf, fix_seed::Bool=true)\n",
    "    # Get number of observations n and number of variables p\n",
    "    n, p = size(x)\n",
    "\n",
    "    # Get number of simulations to use (if simulations are necessary)\n",
    "    R = numSim\n",
    "\n",
    "    # Go through all possible combinations of homoskedasticy/heteroskedasticity\n",
    "    # and X-dependent or independent error terms. The first two cases are\n",
    "    # special cases: Handling the case there homoskedastic was set to None, and\n",
    "    # where lambda_start was provided.\n",
    "    #\n",
    "        \n",
    "    # 1) If homoskedastic was set to None (special case)\n",
    "    if (isnothing(homoskedastic))\n",
    "\n",
    "        # Initialize lambda\n",
    "        lmbda0 = lambda_start\n",
    "\n",
    "        Ups0 = (1 /sqrt(n)) * sqrt.((y.^2)'*(x.^2))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # 2) If lambda_start was provided (special case)\n",
    "    elseif (isnothing(lambda_start)) == 0\n",
    "        \n",
    "        # Check whether a homogeneous penalty term was provided (a scalar)\n",
    "        if maximum(size(lambda_start)) == 1\n",
    "            # If so, repeat that p times as the penalty term\n",
    "            lmbda = ones(p,1).*lambda_start\n",
    "\n",
    "        else\n",
    "            # Otherwise, use the provided vector of penalty terms as is\n",
    "            lmbda = lambda_start\n",
    "        end\n",
    "\n",
    "    # 3) Homoskedastic and X-independent\n",
    "    elseif homoskedastic == true &&  X_dependent_lambda == false\n",
    "\n",
    "        # Initilaize lambda\n",
    "        lmbda0 = 2 * c * sqrt(n) * quantile(Normal(0.0, 1.0),1 - gamma/(2*p))\n",
    "\n",
    "        # Use ddof=1(corrected = true in Julia) to be consistent with R's var() function (in Julia by defaul the DDF is N-1)\n",
    "        Ups0 = sqrt(var(y, corrected = true))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = zeros(p,1) .+ lmbda0 * Ups0\n",
    "\n",
    "    # 4) Homoskedastic and X-dependent\n",
    "    elseif homoskedastic == true && X_dependent_lambda == true\n",
    "\n",
    "        psi = mean.(eachcol(x.^2))\n",
    "        tXtpsi = (x' ./ sqrt(psi))'\n",
    "\n",
    "        R = 5000\n",
    "        sim = zeros(R,1)\n",
    "\n",
    "        for l in 1:R\n",
    "                g = reshape(repeat(randn(n), inner = p),(p, n))'\n",
    "                sim[l] = n * maximum(2*abs.(mean.(eachcol(tXtpsi.* g))))\n",
    "        end\n",
    "\n",
    "        # Initialize lambda based on the simulated quantiles\n",
    "        lmbda0 = c*quantile(vec(sim), 1 - gamma)\n",
    "\n",
    "        Ups0 = sqrt(var(y, corrected = true))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = zeros(p,1) .+ lmbda0 * Ups0\n",
    "\n",
    "    # 5) Heteroskedastic and X-independent\n",
    "    elseif homoskedastic == false &&  X_dependent_lambda == false\n",
    "\n",
    "        # The original includes the comment, \"1=num endogenous variables\"\n",
    "        lmbda0 = 2 * c * sqrt(n) * quantile(Normal(0.0, 1.0),1 - gamma/(2*p*1))\n",
    "\n",
    "        Ups0 = (1 /sqrt(n)) * sqrt.((y.^2)'*(x.^2))'\n",
    "        \n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # 6) Heteroskedastic and X-dependent\n",
    "    elseif homoskedastic == false &&  X_dependent_lambda == true\n",
    "\n",
    "        eh = y\n",
    "        ehat = reshape(repeat(eh, inner = p),(p, n))'\n",
    "\n",
    "        xehat = x.*ehat\n",
    "        psi = mean.(eachcol(xehat.^2))'\n",
    "        tXehattpsi = (xehat./sqrt.(psi))\n",
    "\n",
    "        R = 5000\n",
    "        sim = zeros(R,1)\n",
    "\n",
    "        for l in 1:R\n",
    "                g = reshape(repeat(randn(n), inner = p),(p, n))'\n",
    "                sim[l] = n * maximum(2*abs.(mean.(eachcol(tXtpsi.* g))))\n",
    "        end\n",
    "\n",
    "        # Initialize lambda based on the simulated quantiles\n",
    "        lmbda0 = c*quantile(vec(sim), 1 - gamma)\n",
    "\n",
    "        Ups0 = (1 /sqrt(n)) * sqrt.((y.^2)'*(x.^2))\n",
    "\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    end\n",
    "    return Dict(\"lambda0\" => lmbda0, \"lambda\" => lmbda, \"Ups0\" => Ups0) \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eabd39",
   "metadata": {},
   "source": [
    "# 3.2 rlasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b787b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere mutable struct rlasso_arg\n",
    "    x::DataFrame\n",
    "    y::DataFrame\n",
    "    colnames::Nothing\n",
    "    #rlasso_arg_v2(colnames=nothing) = new(colnames)\n",
    "    post::Bool\n",
    "    intercept::Bool\n",
    "    model::Bool\n",
    "    homoskedastic::Bool\n",
    "    X_dependent_lambda::Bool\n",
    "    lambda_start::Nothing\n",
    "    #rlasso_arg_v2(lambda_start=nothing) = new(lambda_start)\n",
    "    c::Float64\n",
    "    gamma::Nothing\n",
    "    #rlasso_arg_v2(lambda_start=nothing) = new(gamma)\n",
    "    numSim::Int\n",
    "    numIter::Int\n",
    "    tol::Float64 \n",
    "    threshold::Float64\n",
    "    par::Bool\n",
    "    corecap::Float64\n",
    "    fix_seed::Bool\n",
    "end\n",
    "\n",
    "\n",
    "# function rlasso(self::rlasso_arg_4)\n",
    "#     return self.x\n",
    "# end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "610b2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function rlasso(self::rlasso_arg)\n",
    "    \n",
    "    # Import relevant packages for splitting data\n",
    "    #using LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, Tables, TableOperations, StatsBase, FreqTables, DataFrames\n",
    "    \n",
    "    # Initialize internal variables\n",
    "    if self.x isa DataFrame && isnothing(self.colnames)\n",
    "        colnames = names(self.x)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    x = Matrix(self.x)\n",
    "    y = vec(Matrix(self.y))\n",
    "    \n",
    "    n = size(x)[1]\n",
    "    p = size(x)[2]\n",
    "    \n",
    "    if self.x isa DataFrame ==0 && isnothing(self.colnames)\n",
    "        V = []\n",
    "                \n",
    "        for i in 1:p\n",
    "            a = \"V\" * string(i)\n",
    "            V = append!(V, [a])\n",
    "        end\n",
    "        \n",
    "        colnames  = V\n",
    "    else\n",
    "        colnames = colnames\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # Unused line in the original code\n",
    "    # ind_names = np.arange(self.p) + 1\n",
    "    \n",
    "    post               = self.post\n",
    "    intercept          = self.intercept\n",
    "    model              = self.model\n",
    "    homoskedastic      = self.homoskedastic\n",
    "    X_dependent_lambda = self.X_dependent_lambda\n",
    "    lambda_start       = self.lambda_start\n",
    "    c                  = self.c\n",
    "\n",
    "    if isnothing(self.gamma)\n",
    "        gamma = .1 / log(n)\n",
    "    \n",
    "    else\n",
    "        gamma = self.gamma\n",
    "    end\n",
    "    \n",
    "    numSim    = self.numSim\n",
    "    numIter   = self.numIter\n",
    "    tol       = self.tol\n",
    "    threshold = self.threshold\n",
    "\n",
    "    par       = self.par\n",
    "    corecap   = self.corecap\n",
    "    fix_seed  = self.fix_seed\n",
    "    \n",
    "    if self.post == false && isnothing(self.c)\n",
    "        c = 0.5\n",
    "    end\n",
    "    \n",
    "    if ( (self.post == false) && (self.homoskedastic == false)\n",
    "            && (self.X_dependent_lambda == false)\n",
    "            && (isnothing(self.lambda_start)) \n",
    "            && (self.c == 1.1)\n",
    "            && (self.gamma == 0.1 / log(n)) )\n",
    "        \n",
    "        c = .5\n",
    "    end\n",
    "    \n",
    "    # For now, instantiate estimate as None\n",
    "    est = nothing\n",
    "    \n",
    "    \n",
    "    # Calculate robust LASSO coefficients\n",
    "    if self.intercept == true\n",
    "        meanx = mean.(eachcol(x))\n",
    "        x = x - ones(n, 1) * mean.(eachcol(x))'\n",
    "        mu = mean(y)\n",
    "        y = y .- mu\n",
    "        \n",
    "    else\n",
    "        meanx = zeros(p, 1)\n",
    "        mu = 0\n",
    "    end\n",
    "    \n",
    "    normx = sqrt.(var(x, corrected = true, dims = 2))\n",
    "    Psi = mean.(eachcol(x.^2))\n",
    "    ind = zeros(Bool, p)\n",
    "    \n",
    "    XX = x'*x\n",
    "    Xy = x'*y\n",
    "    \n",
    "    startingval = init_values(x, y)[1]\n",
    "    \n",
    "    pen = lambdaCalculation(;homoskedastic=homoskedastic,\n",
    "                                X_dependent_lambda=X_dependent_lambda,\n",
    "                                lambda_start=lambda_start, c=c,\n",
    "                                gamma=gamma, numSim=numSim,\n",
    "                                y=startingval, x=x, par=par,\n",
    "                                corecap=corecap, fix_seed=fix_seed)\n",
    "\n",
    "    lmbda = vec(pen[\"lambda\"])\n",
    "    lmbda_half = lmbda/2\n",
    "    Ups0 = vec(pen[\"Ups0\"])\n",
    "    Ups1 = vec(pen[\"Ups0\"])\n",
    "    lmbda0 = pen[\"lambda0\"]\n",
    "    \n",
    "    mm = 1\n",
    "    s0 = sqrt.(var(y, corrected = true, dims = 1))\n",
    "    \n",
    "    while mm <= numIter\n",
    "        if mm == 1 && self.post\n",
    "#             coefTemp = LassoShooting_fit(x, y, lmbda/2, XX=XX,\n",
    "#                                       Xy=Xy)[\"coefficients\"]\n",
    "            \n",
    "              global coefTemp = LassoShooting_fit(  ;x=x, y=y, \n",
    "                                lmbda=lmbda_half, \n",
    "                                maxIter = 1000, \n",
    "                                optTol = 10^(-5), \n",
    "                                zeroThreshold = 10^(-6),\n",
    "                                XX = XX, \n",
    "                                Xy = Xy, \n",
    "                                beta_start = nothing)[\"coefficients\"]\n",
    "        else\n",
    "              global coefTemp = LassoShooting_fit(  ;x=x, y=y, \n",
    "                                lmbda=lmbda, \n",
    "                                maxIter = 1000, \n",
    "                                optTol = 10^(-5), \n",
    "                                zeroThreshold = 10^(-6),\n",
    "                                XX = XX, \n",
    "                                Xy = Xy, \n",
    "                                beta_start = nothing)[\"coefficients\"]\n",
    "                \n",
    "        end\n",
    "        \n",
    "        global coefTemp[isnan.(coefTemp)] .= 0\n",
    "            \n",
    "        global ind1 =  broadcast(abs, coefTemp) .> 0\n",
    "        \n",
    "        global x1 = x[:, ind1]\n",
    "        \n",
    "        if size(x1)[2] == 0\n",
    "            if intercept\n",
    "                intercept_value = mean(y .+ mu)\n",
    "                \n",
    "                coefs = zeroz(p+1, 1)\n",
    "                coefs = DataFrame([ append!([\"Intercept\"], colnames), coefs ], :auto)\n",
    "               \n",
    "                #coef = \n",
    "            \n",
    "            else\n",
    "                intercept_value = mean(y)\n",
    "                \n",
    "                coefs = zeroz(p, 1)\n",
    "                \n",
    "                coefs = DataFrame([ colnames, coefs ], :auto)\n",
    "            end\n",
    "            \n",
    "            \n",
    "            global est = Dict(\"coefficients\"=> coefs,\n",
    "                    \"beta\"=> zeroz(p, 1),\n",
    "                    \"intercept\"=> intercept_value,\n",
    "                    \"index\"=> DataFrame([ colnames, zeros(Bool, p) ], :auto),\n",
    "                    \"lambda\"=> lmbda,\n",
    "                    \"lambda0\"=> lmbda0,\n",
    "                    \"loadings\"=> Ups0,\n",
    "                    \"residuals\"=> y .- mean(y),\n",
    "                    \"sigma\"=> var(y, corrected = true, dims = 1),\n",
    "                    \"iter\"=> mm,\n",
    "                    #\"call\"=> Not a Python option\n",
    "                    \"options\"=> Dict(\"post\"=> post, \"intercept\"=> intercept,\n",
    "                                \"ind.scale\"=> ind, \"mu\"=> mu, \"meanx\"=> meanx)\n",
    "                   )\n",
    "                \n",
    "            if self.model\n",
    "                    est[\"model\"] = x\n",
    "            else\n",
    "                est[\"model\"] = nothing\n",
    "            \n",
    "            end \n",
    "            \n",
    "            est[\"tss\"] = sum((y .- mean(y)).^2)\n",
    "            est[\"rss\"] = sum((y .- mean(y)).^2)\n",
    "            est[\"dev\"] = y .- mean(y)\n",
    "        \n",
    "        end \n",
    "        \n",
    "        # Refinement variance estimation\n",
    "        if self.post\n",
    "            \n",
    "            reg = lm(x1, y)\n",
    "            \n",
    "            coefT = coef( lm(x1, y) )\n",
    "            \n",
    "            coefT[isnan.(coefT)] .= 0\n",
    "            \n",
    "            global e1 = y - x1*coef( lm(x1, y) )\n",
    "            \n",
    "            coefTemp[ind1] = coefT\n",
    "            \n",
    "        else\n",
    "            global e1 = y - x1*coefTemp[ind1]\n",
    "            \n",
    "        end\n",
    "        \n",
    "        s1 = sqrt.(var(e1, corrected = true, dims = 1))\n",
    "        #s5 = sqrt.(var(y, corrected = true, dims = 1))\n",
    "        \n",
    "                \n",
    "        # Homoskedastic and X-independent\n",
    "        if (\n",
    "                    (self.homoskedastic == true) \n",
    "                    && (self.X_dependent_lambda == false)\n",
    "            )\n",
    "            \n",
    "            Ups1 = s1 * Psi\n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "            \n",
    "        # Homoskedastic and X-dependent\n",
    "        elseif (\n",
    "                    (self.homoskedastic == true)\n",
    "                    && (self.X_dependent_lambda == true)\n",
    "            )\n",
    "\n",
    "            Ups1 = s1 * Psi\n",
    "\n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "\n",
    "        # Heteroskedastic and X-independent\n",
    "        elseif (\n",
    "                (self.homoskedastic == false)\n",
    "                && (self.X_dependent_lambda == false)\n",
    "            )\n",
    "                        \n",
    "            Ups1 =  (1/sqrt(n)) * sqrt.((e1.^2)' * x.^2)\n",
    "            \n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "        \n",
    "        # Heteroskedastic and X-dependent\n",
    "        elseif (\n",
    "                (self.homoskedastic == false)\n",
    "                && (self.X_dependent_lambda == true)\n",
    "                )\n",
    "            \n",
    "            lc = lambdaCalculation(homoskedastic=homoskedastic,\n",
    "                       X_dependent_lambda=X_dependent_lambda,\n",
    "                       lambda_start=lambda_start,\n",
    "                       c=c, gamma=gamma,\n",
    "                       numSim=numSim, y=e1, x=x,\n",
    "                       par=par, corecap=corecap,\n",
    "                       fix_seed=fix_seed)\n",
    "\n",
    "            Ups1 = lc[\"Ups0\"]\n",
    "\n",
    "            lmbda = lc[\"lambda\"]\n",
    "        \n",
    "        # If homoskedastic is set to None\n",
    "        elseif isnothing(self.homoskedastic)\n",
    "            \n",
    "            Ups1 =  (\n",
    "                    (1/sqrt(n)) * sqrt.((e1.^2) * x.^2)\n",
    "                )\n",
    "            \n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "        end\n",
    "        \n",
    "        mm = mm + 1\n",
    "        \n",
    "        if broadcast(abs, s0 - s1)[1] < self.tol\n",
    "            break\n",
    "            \n",
    "        end\n",
    "        \n",
    "        s0 = s1\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if size(x1)[2] == 0\n",
    "        coefTemp = None\n",
    "        ind1 = zeros(p, 1)\n",
    "    end\n",
    "    \n",
    "    global coefTemp = coefTemp\n",
    "    \n",
    "    coefTemp[broadcast(abs, coefTemp) .< threshold] .= 0\n",
    "    \n",
    "    coefTemp_df = DataFrame([ colnames, coefTemp ], :auto)\n",
    "\n",
    "    global ind1 = ind1\n",
    "    \n",
    "    ind1_df = DataFrame([ colnames, ind1 ], :auto)\n",
    "    \n",
    "    if self.intercept\n",
    "        \n",
    "        if isnothing(mu)\n",
    "            mu = 0\n",
    "        end\n",
    "        \n",
    "        if isnothing(meanx)\n",
    "            meanx = zeros( size(coefTemp)[1], 1)\n",
    "        end\n",
    "        \n",
    "        if sum(ind) == 0\n",
    "            intercept_value = mu - sum(meanx .* coefTemp)\n",
    "        else\n",
    "            intercept_value = mu - sum(meanx .* coefTemp)\n",
    "        end\n",
    "    \n",
    "    else\n",
    "        intercept_value = NaN\n",
    "    end\n",
    "    \n",
    "    #s1 = sqrt.(var(e1, corrected = true, dims = 1))\n",
    "    \n",
    "    if self.intercept\n",
    "        beta = vcat(intercept_value, coefTemp)\n",
    "        \n",
    "        beta = DataFrame([ append!([\"Intercept\"], colnames), beta ], :auto)\n",
    "    \n",
    "    else\n",
    "        beta = coefTemp\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s1 = sqrt.(var(e1, corrected = true, dims = 1))\n",
    "    \n",
    "    \n",
    "    est = Dict(\n",
    "    \"coefficients\"=> beta,\n",
    "    \"beta\"=> DataFrame([ colnames, coefTemp ], :auto), \n",
    "    \"intercept\"=> intercept_value,\n",
    "    \"index\"=> ind1,\n",
    "    \"lambda\"=> DataFrame([ colnames, vec(lmbda) ], :auto),\n",
    "    \"lambda0\"=> lmbda0,\n",
    "    \"loadings\"=> Ups1,\n",
    "    \"residuals\"=> e1,\n",
    "    \"sigma\"=> s1,\n",
    "    \"iter\"=> mm,\n",
    "    #\"call\"=> Not a Python option\n",
    "    \"options\"=> Dict(\"post\"=> self.post, \"intercept\"=> self.intercept,\n",
    "                \"ind.scale\"=> ind, \"mu\"=> mu, \"meanx\"=> meanx),\n",
    "    \"model\"=> model\n",
    "    )\n",
    "    \n",
    "    if model\n",
    "        x = x + ones(n, 1) * mean.(eachcol(x))'\n",
    "        \n",
    "        est[\"model\"] = x\n",
    "        \n",
    "    else\n",
    "        est[\"model\"] = nothing\n",
    "        \n",
    "    end\n",
    "    \n",
    "    est[\"tss\"] = sum((y .- mean(y)).^2)\n",
    "    est[\"rss\"] = sum((y .- mean(y)).^2)\n",
    "    est[\"dev\"] = y .- mean(y)\n",
    "    est[\"Xy\"] = Xy\n",
    "    est[\"startingval\"] = startingval\n",
    "    est[\"pen\"] = pen\n",
    "    est[\"x1\"] = x1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   return est\n",
    "   #return Dict(\"reg\" => reg)\n",
    "   #return coefTemp\n",
    "   #return colnames, coefTemp, lmbda\n",
    "        \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
